{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stemming \n",
    "Stemming is a text preprocessing technique in natural language processing (NLP) that eliminates prefixes and suffixes from words, transforming them into their fundamental or root form.\n",
    "\n",
    "[dancing, dancer, danced, dances] -> dance\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "words = [\n",
    "    \"Running\",\n",
    "    \"Jumps\",\n",
    "    \"Easily\",\n",
    "    \"Friendliness\",\n",
    "    \"Happily\",\n",
    "    \"Eating\",\n",
    "    \"Studies\",\n",
    "    \"Caring\",\n",
    "    \"Organizations\",\n",
    "    \"Cried\",\n",
    "    \"Flying\",\n",
    "    \"Houses\",\n",
    "    \"Wondered\",\n",
    "    \"Playing\",\n",
    "    \"Quicker\",\n",
    "    \"Wolves\",\n",
    "    \"Bigger\",\n",
    "    \"Amazement\",\n",
    "    \"Completely\",\n",
    "    \"Simplified\",\n",
    "    \"Eaten\",\n",
    "    \"History\"\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Porter Stemmer\n",
    "It has disadvantage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\User\\AppData\\Roaming\\nltk_data...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import PorterStemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "porter_stemmer = PorterStemmer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running ---> run\n",
      "Jumps ---> jump\n",
      "Easily ---> easili\n",
      "Friendliness ---> friendli\n",
      "Happily ---> happili\n",
      "Eating ---> eat\n",
      "Studies ---> studi\n",
      "Caring ---> care\n",
      "Organizations ---> organ\n",
      "Cried ---> cri\n",
      "Flying ---> fli\n",
      "Houses ---> hous\n",
      "Wondered ---> wonder\n",
      "Playing ---> play\n",
      "Quicker ---> quicker\n",
      "Wolves ---> wolv\n",
      "Bigger ---> bigger\n",
      "Amazement ---> amaz\n",
      "Completely ---> complet\n",
      "Simplified ---> simplifi\n",
      "Eaten ---> eaten\n",
      "History ---> histori\n"
     ]
    }
   ],
   "source": [
    "for word in words:\n",
    "    print(word + ' ---> ' + porter_stemmer.stem(word))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import RegexpStemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "reg_stemmer = RegexpStemmer('ing$|s$|ables$', min=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'eat'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reg_stemmer.stem('eating')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Snowball Stemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import SnowballStemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "snowball_stemmer = SnowballStemmer('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running-----> run\n",
      "Jumps-----> jump\n",
      "Easily-----> easili\n",
      "Friendliness-----> friendli\n",
      "Happily-----> happili\n",
      "Eating-----> eat\n",
      "Studies-----> studi\n",
      "Caring-----> care\n",
      "Organizations-----> organ\n",
      "Cried-----> cri\n",
      "Flying-----> fli\n",
      "Houses-----> hous\n",
      "Wondered-----> wonder\n",
      "Playing-----> play\n",
      "Quicker-----> quicker\n",
      "Wolves-----> wolv\n",
      "Bigger-----> bigger\n",
      "Amazement-----> amaz\n",
      "Completely-----> complet\n",
      "Simplified-----> simplifi\n",
      "Eaten-----> eaten\n",
      "History-----> histori\n"
     ]
    }
   ],
   "source": [
    "for word in words:\n",
    "    print(word + \"----->\", snowball_stemmer.stem(word))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('fairli', 'sportingli')"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "porter_stemmer.stem(\"fairly\"), porter_stemmer.stem(\"sportingly\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('fair', 'sport')"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "snowball_stemmer.stem(\"fairly\"), snowball_stemmer.stem(\"sportingly\") # It is better than porter stemmer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Wordnet Lemmatization \n",
    "Lemmatization in linguistics is the process of grouping together the inflected forms of a word so they can be analysed as a single item, identified by the word's lemma, or dictionary form. Lemmatization is better than stem as it takes a root word rather than root stem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import WordNetLemmatizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "lemmatizer = WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'going'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lemmatizer.lemmatize('going')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'go'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lemmatizer.lemmatize('going', pos='v')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running--->Running\n",
      "Jumps--->Jumps\n",
      "Easily--->Easily\n",
      "Friendliness--->Friendliness\n",
      "Happily--->Happily\n",
      "Eating--->Eating\n",
      "Studies--->Studies\n",
      "Caring--->Caring\n",
      "Organizations--->Organizations\n",
      "Cried--->Cried\n",
      "Flying--->Flying\n",
      "Houses--->Houses\n",
      "Wondered--->Wondered\n",
      "Playing--->Playing\n",
      "Quicker--->Quicker\n",
      "Wolves--->Wolves\n",
      "Bigger--->Bigger\n",
      "Amazement--->Amazement\n",
      "Completely--->Completely\n",
      "Simplified--->Simplified\n",
      "Eaten--->Eaten\n",
      "History--->History\n"
     ]
    }
   ],
   "source": [
    "for word in words:\n",
    "    print(word + \"--->\" + lemmatizer.lemmatize(word))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running--->Running\n",
      "Jumps--->Jumps\n",
      "Easily--->Easily\n",
      "Friendliness--->Friendliness\n",
      "Happily--->Happily\n",
      "Eating--->Eating\n",
      "Studies--->Studies\n",
      "Caring--->Caring\n",
      "Organizations--->Organizations\n",
      "Cried--->Cried\n",
      "Flying--->Flying\n",
      "Houses--->Houses\n",
      "Wondered--->Wondered\n",
      "Playing--->Playing\n",
      "Quicker--->Quicker\n",
      "Wolves--->Wolves\n",
      "Bigger--->Bigger\n",
      "Amazement--->Amazement\n",
      "Completely--->Completely\n",
      "Simplified--->Simplified\n",
      "Eaten--->Eaten\n",
      "History--->History\n"
     ]
    }
   ],
   "source": [
    "for word in words:\n",
    "    print(word + \"--->\" + lemmatizer.lemmatize(word, pos='v'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('fairly', 'sportingly')"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lemmatizer.lemmatize(\"fairly\"), lemmatizer.lemmatize(\"sportingly\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".nlpenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
